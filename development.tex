% !TeX root = main.tex
\chapter{Vector Fields in Matrix Lie Groups}\label{ch:vector_field}
Our main objective is to develop a vector field strategy that guides a system to follow a curve $\mathcal{C}$ in a Lie group. In this chapter, we build upon the concepts introduced in \cref{sec:background-lie-theory} to develop the tools necessary for generalizing the results of \citet{Rezende2022} to any connected matrix Lie group. We start by defining some useful operators that will aid in the development of our results. Next, we introduce two distance functions: one that measures the distance between arbitrary group elements and another that measures the distance between an element and a curve. These distance functions are fundamental to defining the vector field components. As we will show, the properties of orthogonality and the absence of local minima are directly related to the properties of the distance function. With all the concepts in place, we present our main theorem, which guarantees the convergence and circulation of the target curve.

In this chapter, we adopt $G$ as a connected matrix Lie group of dimension $m$ (the degrees of freedom of the group), whose representation is an $n\times n$ matrix. Given \cref{lemma:very-important-fact}, we will \emph{assume} that our control system is given by
\begin{align}
    \dot{\mathbf{H}}(t)=\SL\bigl(\boldsymbol{\xi}(t)\bigr)\mathbf{H}(t),
    \label{eq:derivative-H-SL-considered-system}
\end{align}
in which $\mathbf{H}$ $\in G$ is the state variable and $\boldsymbol{\xi} \in \mathbb{R}^m$ is the control input. 

For a practical example, let $G=\text{SE}(3)$ (thus $n=4$, $m=6$), with $\mathbf{H}\in\text{SE}(3)$ representing the pose of an omnidirectional UAV in a fixed frame. By properly selecting the basis $\mathbf{E}_k$, $\boldsymbol{\xi}\in\mathbb{R}^6$ corresponds to a twist in the world frame, representing the UAV's linear and angular velocities. This control system setup assumes arbitrary control over the UAV's 6-DoF twist, a reasonable model for an omnidirectional UAV. Analogously, we henceforth refer to $\boldsymbol{\xi}\in\mathbb{R}^m$ as the \emph{generalized twist}. 

Similar to the single integrator system model of \citet{Rezende2022}, the model in \eqref{eq:derivative-H-SL-considered-system} assumes maximal control freedom within the constraints of the Lie group. This means each component of $\boldsymbol{\xi}$ can be independently controlled, enabling arbitrary motion of an element $\mathbf{H}\in G$ while ensuring that $\mathbf{H}(t)$ remains within the group. Additionally, both systems exhibit first-order dynamics: their trajectories are governed by velocities rather than higher-order terms (e.g., accelerations or torques).

\begin{remark}
    The results presented in this chapter also apply to systems of the form $\dot{\mathbf{H}} = \mathbf{H} \mathcal{S}'(\boldsymbol{\xi}')$, where $\mathcal{S}'$ is an appropriate isomorphism mapping $\mathbb{R}^m$ to $\mathfrak{g}$. For instance, considering the UAV example, this system could model a UAV controlled via the twist in the \emph{body frame} rather than the \emph{fixed frame}. This adaptation can be achieved by rewriting \eqref{eq:derivative-H-SL-considered-system} as $\dot{\mathbf{H}} = \mathbf{H}(\mathbf{H}^{-1} \SL[\boldsymbol{\xi}] \mathbf{H})$. It is well known in the context of Lie groups (see \citet[p. 86]{Gallier2020}) that for any $\mathbf{A} \in \mathfrak{g}$ and $\mathbf{H} \in G$, the term $\mathbf{H}^{-1} \mathbf{A} \mathbf{H}$ also belongs to $\mathfrak{g}$. Therefore, there exists a unique $\boldsymbol{\xi}' \in \mathfrak{g}$ such that $\mathcal{S}'(\boldsymbol{\xi}') = \mathbf{H}^{-1} \SL[\boldsymbol{\xi}] \mathbf{H}$, since $\mathcal{S}'$ is a bijection. This correspondence enables the calculation of a controller for the modified system based on the controller designed for the original system.
\end{remark}

We begin with the definition of the operators that will be used to extract information from the group elements.
\section{Operators and derivatives}
According to \cref{lemma:very-important-fact}, for each differentiable function $\mathbf{G}: \mathbb{R} \to G$ there exists a respective function $\boldsymbol{\zeta} \in \mathbb{R}^m$ according to equation \eqref{eq:importantresult}. Thus, we will define the following operator that extracts this $\boldsymbol{\zeta}(\sigma)$ from $\mathbf{G}(\sigma)$:
\begin{definition} [$\Xi$ operator] \label{def:Xioperator} Let $G$ be an $m$-dimensional Lie group. Given a choice of S map $\SL: \mathbb{R}^m \to \mathfrak{g}$, the respective $\Xi$ operator maps a differentiable function $\mathbf{G}: \mathbb{R} \to G$ into a function $\Xi[\mathbf{G}]: \mathbb{R} \to \mathbb{R}^m$ as $\Xi[\mathbf{G}](\sigma) = \SL^{-1}\bigl(\frac{d\mathbf{G}}{d\sigma}(\sigma)\mathbf{G}(\sigma)^{-1}\bigr)$. 
\end{definition}

In our development, it will be necessary to take derivatives along the manifold $G$. This is related to the concept of \emph{Lie derivatives} (see \cref{app:Lop-and-Lie-derivative}). For this purpose, the following definition will be useful.
\begin{definition} [\text{L} operator] \label{def:Loperator} Let $G$ be an $m$-dimensional Lie group and $\mathbf{G}\in G$. Given a choice of $S$ map and a differentiable function $f: G \to \mathbb{R}$, we define the \text{L} operator such that the function $\text{L}[f] : G \to \mathbb{R}^{1 \times m}$ satisfies:
\begin{equation}
\label{eq:Leq}
    \lim_{\varepsilon \rightarrow 0} \frac{1}{\varepsilon} \Biggl( f\Bigl(\exp\bigl(\SL[\boldsymbol{\zeta}]\varepsilon\bigr)\mathbf{G}\Bigr) - f(\mathbf{G}) \Biggr) = \text{L}[f](\mathbf{G}) \boldsymbol{\zeta}, \ \forall\, \boldsymbol{\zeta} \in \mathbb{R}^m.
\end{equation}
Explicitly, the $j^{th}$ entry of the row vector $\text{L}[f](\mathbf{G})$ can be constructed as the left-hand side of \eqref{eq:Leq} when $\boldsymbol{\zeta} = \mathbf{e}_j$. The expression \eqref{eq:Leq} is also representable with derivatives:
\begin{align}
    \left.\frac{d}{d\varepsilon}\biggl(f\Bigl(\exp\bigl(\SL[\boldsymbol{\zeta}]\varepsilon\bigr)\mathbf{G}\Bigr)\biggr)\right|_{\varepsilon=0} = \text{L}[f](\mathbf{G})\boldsymbol{\zeta},\ \forall\, \boldsymbol{\zeta} \in \mathbb{R}^m.
    \label{eq:L-operator-derivative-form}
\end{align}

In addition, if $f: G \times G \to \mathbb{R}$ is a function of two variables, $f(\mathbf{V},\mathbf{W})$, we define the \emph{partial} L operators $\text{L}_{\mathbf{V}}$ and $\text{L}_{\mathbf{W}}$ analogously as in \eqref{eq:Leq} but making the variation only in the first or in the second variable, respectively. 
\end{definition}

The following version of the chain rule using the \text{L} operator can be established.

\begin{lemma}\label{lemma:chainrule}
    Let $G$ be an $m$-dimensional Lie group. Let $\mathbf{G} : \mathbb{R} \to G$ and $f: G \to \mathbb{R}$ be differentiable functions. Then:
    \begin{align}
       \frac{d}{d\sigma} f\bigl(\mathbf{G}(\sigma)\bigr) = \textnormal{L}[f]\bigl(\mathbf{G}(\sigma)\bigr)\Xi[\mathbf{G}](\sigma).
    \end{align}
\end{lemma}
\begin{proof}
    Let $\boldsymbol{\zeta}(\sigma) = \Xi[\mathbf{G}](\sigma)$. According to \cref{lemma:very-important-fact} and \cref{def:Xioperator}, we have
    \begin{align*}
        \frac{d}{d\sigma'}\mathbf{G}(\sigma') = \SL[\boldsymbol{\zeta}(\sigma')]\mathbf{G}(\sigma').
    \end{align*}
    If $\SL[\boldsymbol{\zeta}(\sigma')]$ was constant, meaning $\boldsymbol{\zeta}$ is constant, a solution to this system would be given by
    \begin{align*}
        \mathbf{G}(\sigma') = \exp\bigl((\sigma'-\sigma'_0)\SL[\boldsymbol{\zeta}]\bigr)\mathbf{G}(\sigma'_0).
    \end{align*}

    Take a small $\varepsilon >0$ such that $\sigma'=\sigma+\varepsilon \approx \sigma$, and let $\sigma'_0=\sigma$. Thus, $\boldsymbol{\zeta}(\sigma')$ is approximately constant, and we can write $\mathbf{G}(\sigma+\varepsilon) \approx \exp(\SL[\boldsymbol{\zeta}(\sigma)]\varepsilon)\mathbf{G}(\sigma)$. 
    Applying the definition of the traditional derivative:
    \begin{align}
        \begin{split}
            \frac{d}{d\sigma} f\bigl(\mathbf{G}(\sigma)\bigr) &= \lim_{\varepsilon \rightarrow 0} \frac{f\bigl(\mathbf{G}(\sigma+\varepsilon)\bigr){-}f\bigl(\mathbf{G}(\sigma)\bigr)}{\varepsilon}\\
            &  =
            \lim_{\varepsilon \rightarrow 0} \frac{f\bigl(\exp(\SL[\boldsymbol{\zeta}(\sigma)]\varepsilon)\mathbf{G}(\sigma)\bigr){-}f\bigl(\mathbf{G}(\sigma)\bigr)}{\varepsilon} = \text{L}[f](\mathbf{G}) \boldsymbol{\zeta}(\sigma),      
        \end{split}
    \end{align}
    in which the defining property of $\text{L}[f]$ in equation \eqref{eq:Leq} was applied. This concludes the proof.
\end{proof}

As a consequence of \cref{lemma:chainrule}, we can establish the following corollary.

\begin{corollary} \label{corol:corol1} If we have a function $f: G \times G \to \mathbb{R}$ instead of a function of a single variable, and two differentiable functions $\mathbf{V}, \mathbf{W} : \mathbb{R} \to G$, then:
\begin{equation}
   \frac{d}{d \sigma} f(\mathbf{V},\mathbf{W}) {=} \textnormal{L}_{\mathbf{V}}[f] \Xi[\mathbf{V}] {+} \textnormal{L}_{\mathbf{W}}[f] \Xi[\mathbf{W}],
\end{equation}
in which the dependency on $\mathbf{V}, \mathbf{W}$ and $\sigma$ was omitted on the right-hand side. 
\end{corollary}

Further properties of the $\Lop$ operator are investigated in \cref{app:properties-L-op}.

\section{Vector field formulation}
\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        block/.style={draw, rectangle, minimum height=1.2cm, minimum width=2.4cm, align=center},
        arrow/.style={->, >=stealth, thick},
        label/.style={font=\small}
    ]
    
    % Nodes
    \node[block] (controller) {Vector Field};
    \node[block, right=2cm of controller] (plant) {System};
    % \node[block, below=1cm of plant] (estimation) {Estimation of $\theta_c$};
    
    % Arrows between blocks
    \draw[arrow] (controller) -- node[above, label] {$\Psi(\mathbf{H})$} (plant);
    % Input and Output Arrows
    \node[left=1.5cm of controller, yshift=0.25cm] (input) {Curve $\mathcal{C}\subset G$};
    \draw[arrow] (input) -- ($(controller.west)+(0,0.25)$);    
    \node[right=1.5cm of plant] (output) {$\mathbf{H}(t)\in G$};
    \draw[arrow] (plant.east) -- (output);    
    % Feedback loop
    % \draw[arrow] ($(plant.east)+(0.75,0)$) |- ++(0,-1.5) -| (aux) -| ($(controller.west)+(0,-0.25)$);
    \draw[arrow] 
    ($(plant.east)+(0.75,0)$) |- ++(0,-1.25)
    -|  ($(controller.west)+(-0.75,-0.25)$)                          
    -- ($(controller.west)+(0,-0.25)$);

    \end{tikzpicture}
    \caption{Block diagram of the kinematic control using the vector field guidance.}
    \label{fig:kinematic-control-diagram}
\end{figure}

Following the same steps as in \cref{sec:adriano-review}, we propose a vector field strategy that ensures both convergence to and circulation around a curve $\mathcal{C}$ defined in a Lie group $G$, adopting the system in \eqref{eq:derivative-H-SL-considered-system}. We assume that this curve is differentiable and without self-intersections. Thus, we aim to synthesize a state feedback control law $\boldsymbol{\xi}=\Psi\left(\mathbf{H}\right)$ to achieve this. Let $\mathbf{H}_d:[0,1] \to G$ be a differentiable parametrization for the target curve $\mathcal{C}$. The proposed vector field is then expressed as:
\begin{align}
    \Psi\left(\mathbf{H}\right) \triangleq k_N(\mathbf{H})\boldsymbol{\xi}_N(\mathbf{H}) + k_T(\mathbf{H})\boldsymbol{\xi}_T(\mathbf{H}), \label{eq:vector-field-proposition}
\end{align}
where the \emph{normal} component $\boldsymbol{\xi}_N$ ensures convergence, and the \emph{tangent} component $\boldsymbol{\xi}_T$ governs circulation. These components will be formally defined later. In this case, $k_N: G \to \mathbb{R}$ and $k_T: G \to \mathbb{R}$ are continuous functions in which $k_T(\mathbf{H})$ is positive and $k_N(\mathbf{H})=0$ when $\mathbf{H} \in \mathcal{C}$ and $k_N(\mathbf{H}) > 0$ otherwise. The block diagram of this control strategy is shown in \cref{fig:kinematic-control-diagram}.
\begin{remark}
    The proposed results generalize the vector field approach by \citet{Rezende2022}, as outlined in \cref{sec:adriano-review}. Throughout this section, we will specify the choices required to reduce the proposed approach to that of \citet{Rezende2022}. To align with their results, the group $G$ in our framework should be taken as the \emph{$m$-dimensional translation group}, denoted by $\text{T}(m)$ (see \cref{ex:translation-group}). Notably, \citet{Rezende2022} do not use the Lie group formalism, instead working with vectors---a feasible approach because each element of $\text{T}(m)$ corresponds uniquely to a vector in $\mathbb{R}^m$. To facilitate the connection between both works, we will also adopt this vector representation, using the isomorphism $\mathcal{T}: \text{T}(m) \to \mathbb{R}^m$, where $\mathcal{T}(\mathbf{H})$ is obtained by extracting the first $m$ elements of the last column of $\mathbf{H}$. Henceforth, we take as a basis of the Lie algebra of $\text{T}(m)$ the matrices $\mathbf{E}_k$, $k \in \{1,2,\dots,m\}$, where $\mathbf{E}_k$ has all entries $0$ except for the $k^{th}$ entry of the last column, which is $1$. With this choice, the system \eqref{eq:derivative-H-SL-considered-system} reduces to the single integrator model used by \citet{Rezende2022}, as $\frac{d}{dt} \mathcal{T}(\mathbf{H}) = \boldsymbol{\xi}$.  
\end{remark}

For the vector field computation, we need to measure the distance between an element and a curve within the Lie group. Thus, we first define a distance function $\widehat{D}$ between arbitrary elements $\mathbf{V}$ and $\mathbf{W}$ in the group, as follows.
\begin{definition}[EE-distance function]\label{def:distance-D-hat-arbitrary-elements}
    Let $G$ be a Lie group. We call $\widehat{D}:G\times G\to \mathbb{R}_+$ an \emph{Element-to-Element} \emph{(EE-)distance function}, a function that measures the distance between elements $\mathbf{V}, \mathbf{W}\in G$ with the following properties: 
    \begin{property}
        \item (Positive Definiteness) $\widehat{D}(\mathbf{V}, \mathbf{W}) \ge 0$ and $\widehat{D}(\mathbf{V}, \mathbf{W})$ $= 0 \iff \mathbf{V}=\mathbf{W}$;\label{prop:Dhat-positive-definite}
        \item (Differentiability) $\widehat{D}$ is at least once differentiable in both arguments almost everywhere, that is, the limit in \eqref{eq:Leq} should exist. In addition, there should exist $D_{\text{min},\mathcal{C}}>0$ such that the derivative exists when $0 < \widehat{D} < D_{\text{min},\mathcal{C}}$. Finally, where the derivative does not exist, every directional limit should exist (although they do not need to be equal) and be bounded. \label{prop:Dhat-differentiability}
    \end{property}
\end{definition}

\begin{example}\label{ex:adriano-distance-function}
    To obtain the results by \citet{Rezende2022}, $\widehat{D}$ should be taken as the Euclidean distance between the respective position vectors $\widehat{D}(\mathbf{V}, \mathbf{W}) = \|\mathcal{T}(\mathbf{V}) - \mathcal{T}(\mathbf{W})\|$. 
\end{example}

By allowing the function to be non-differentiable in certain cases, we can incorporate important distance functions, such as the Euclidean distance $\widehat{D}(\mathbf{V},\mathbf{W}) = \|\mathcal{T}(\mathbf{V}) - \mathcal{T}(\mathbf{W})\|$ when $G=\text{T}(m)$. This  is not differentiable at $\mathbf{V}=\mathbf{W}$, but all directional limits of the derivatives exist and are bounded. Furthermore, although it is not differentiable when $\widehat{D}=0$, it is differentiable everywhere else, so $D_{\text{min},\mathcal{C}} = \infty$ can be taken. Overall, the (possible) non-differentiability when $\mathbf{V}=\mathbf{W}$  for a generic $\widehat{D}$ will not be an issue since it will be canceled in the final controller, as will be clear soon.

Now, a distance between an element $\mathbf{H}$ to the curve $\mathcal{C}$ is defined as the minimum distance, as measured by $\widehat{D}$, between $\mathbf{H}$ and any $\mathbf{Y}$ in the curve. 
\begin{definition}[EC-Distance Function]\label{def:distance-D-element-curve}
    Given an EE-distance function as in \cref{def:distance-D-hat-arbitrary-elements}, an \emph{Element-to-Curve (EC-)}distance function $D: G\to\mathbb{R}_+$ measures the distance between an element $\mathbf{H}$ and a curve $\mathcal{C}$ parameterized by $\mathbf{H}_d(s)$. It is defined as:
    \begin{align}
        D(\mathbf{H}) \triangleq \min_{\mathbf{Y}\in\mathcal{C}}\widehat{D}(\mathbf{H}, \mathbf{Y}) =
        \min_{s\in[0,1]} \widehat{D}\bigl(\mathbf{H}, \mathbf{H}_d(s)\bigr).\label{eq:optimization-problem-distance-definition-point-curve}
    \end{align}
    Furthermore, let $\mathcal{P}_1\subset G$ be the set of elements $\mathbf{H}$ such that the optimization problem in \eqref{eq:optimization-problem-distance-definition-point-curve} does not have a unique solution. In addition, we define $s^*: G \to [0,1]$ so, when $\mathbf{H}\notin \mathcal{P}_1$, $s^*(\mathbf{H})$ is the unique minimizer on $s$ for the given $\mathbf{H}$. %When $\mathbf{H}\in \mathcal{P}_1$, we define $s^*(\mathbf{H})$ in a pre-established deterministic manner as one of the possible minimizers $s$.
    We also define $\mathcal{P}_2$ as the set of elements $\mathbf{H} \not \in (\mathcal{P}_1 \cup \mathcal{C})$ such that $\mathbf{V} = \mathbf{H}$, $\mathbf{W} = \mathbf{H}_d\bigl(s^*(\mathbf{H})\bigr)$ is a non-differentiability point of $\widehat{D}(\mathbf{V},\mathbf{W})$. Finally, we define $\mathcal{P} \triangleq \mathcal{P}_1 \cup \mathcal{P}_2$.
\end{definition}
Note that, from the definition of $\mathcal{P}$, $\mathcal{C} \cap \mathcal{P} = \emptyset$. Furthermore, the fact that $D_{\text{min},\mathcal{C}}>0$ in \cref{def:distance-D-hat-arbitrary-elements} means that there is a non-zero separation distance\footnote{``Distance'' refers to any metric (e.g., Euclidean). The non-zero distance implies a strict gap between sets, not merely disjointness.} between $\mathcal{P}$ and $\mathcal{C}$. For the sake of notational simplicity, we will often omit the dependency of $s^*$ on $\mathbf{H}$ and write simply $s^*$ instead of $s^*(\mathbf{H})$.

Before we define the vector field components, we will state a lemma that will be extensively used to prove many other lemmas and propositions throughout this work. For that, it will be useful to define $\boldsymbol{\xi}_d$, the \emph{generalized twist} $\boldsymbol{\xi}$ in \eqref{eq:derivative-H-SL-considered-system} with which the system will be able to follow the desired curve at a given $\mathbf{H}=\mathbf{H}_d(s)$.
\begin{definition}[Curve twist] \label{def:XId-twist-Hd-for-tangent}
    Let $\boldsymbol{\xi}_d(s) \triangleq \Xi[\mathbf{H}_d](s)$ (see \cref{def:Xioperator}). Furthermore, we call the parametrization $\mathbf{H}_d(s)$ \emph{proper} if $\boldsymbol{\xi}_d(s) \neq \mathbf{0}$ for all $s \in [0,1]$.
\end{definition}
Having a proper parametrization is a purely geometric feature of the curve $\mathcal{C}$. The non-self-intersection property of the curve $\mathcal{C}$ implies that $\mathbf{H}_d: [0,1] \to \mathcal{C}$ is bijective and thus any non-proper parametrization can be transformed into a proper one through reparametrization (e.g., arc length parametrization). With this definition, we can proceed with the following useful lemma.
\begin{lemma}\label{lemma:optimization-problem-part-hdi-vanishers}
    When $\mathbf{H} \notin \mathcal{C} \cup \mathcal{P}$ , the first order optimality condition of \eqref{eq:optimization-problem-distance-definition-point-curve} implies that 
    \begin{equation}
    \textnormal{L}_{\mathbf{W}}[\widehat{D}]\bigl(\mathbf{H},\mathbf{H}_d(s^*)\bigr)\boldsymbol{\xi}_d(s^*) = 0.
    \end{equation}
\end{lemma}
\begin{proof}
    Let $\mathbf{H}\in G$, $\mathbf{H} \notin \mathcal{C} \cup \mathcal{P}$ be an arbitrary element, $\mathbf{H}_d(s)\in G$ the parametrization of a curve, and $D$ an EC-distance defined as in \cref{def:distance-D-element-curve}. Since $D$ is the minimum value of an EE-distance function $\widehat{D}$ (see \cref{def:distance-D-hat-arbitrary-elements}), by the first order optimality condition of \eqref{eq:optimization-problem-distance-definition-point-curve} we know that the optimal parameter $s^*$ will render $\frac{d}{ds}\widehat{D}(\mathbf{H}, \mathbf{H}_d(s))|_{s=s^*}=0$. Taking the derivative at $s=s^*$, using \cref{corol:corol1}, \cref{def:XId-twist-Hd-for-tangent} and setting it to zero, we obtain the desired result. Furthermore, since $\mathbf{H} \not\in \mathcal{C} \cup \mathcal{P}$, the function $\widehat{D}$ is guaranteed to be differentiable.  
\end{proof}
\section{Normal component}
Following the same steps as in \cref{sec:adriano-review}, after defining our EC-distance function, we state our vector field components. To define our \emph{normal} component, we build upon \cref{feat:adriano-time-derivative-lyapunov-normal-comp} (in page \pageref{feat:adriano-time-derivative-lyapunov-normal-comp}). By differentiating $D$, we denote the opposite of the term that multiplies the generalized twist $\boldsymbol{\xi}$ as the normal component. We begin with the following lemma.
\begin{lemma}\label{lemma:time-derivative-of-distance-function}
    When $\mathbf{H}(t) \not \in \mathcal{C} \cup \mathcal{P}$, the time derivative of an EC-distance $D(\mathbf{H}(t))$, under the dynamics in \eqref{eq:derivative-H-SL-considered-system}, is given by 
    \begin{align}
        \frac{d}{dt}{D} = \textnormal{L}[D](\mathbf{H})\boldsymbol{\xi} =  \textnormal{L}_{\mathbf{V}}[\widehat{D}]\bigl(\mathbf{H},\mathbf{H}_d(s^*)\bigr)\boldsymbol{\xi}. \label{eq:final-equation-for-normal-component}
    \end{align}
\end{lemma}
\begin{proof}
The first part of the equation comes from the chain rule in \cref{lemma:chainrule} and \eqref{eq:derivative-H-SL-considered-system}. For the second equality, use the fact that $D(\mathbf{H}) = \widehat{D}\bigl(\mathbf{H},\mathbf{H}_d(s^*(\mathbf{H}))\bigr)$ and differentiate applying the chain rule using \cref{corol:corol1}:
    \begin{align}
    \dot{D} = \text{L}_{\mathbf{V}}[\widehat{D}]\boldsymbol{\xi} + \bigg(\text{L}_{\mathbf{W}}[\widehat{D}] \boldsymbol{\xi}_d\bigg) \frac{ds^*}{dt} \label{eq:part-of-proof-use-optimallity-cond}
\end{align}
in which the dependencies of $\text{L}_{\mathbf{V}}$ and $\text{L}_{\mathbf{W}}$ on $\mathbf{H}$ and $\mathbf{H}_d(s^*)$ were omitted. By \cref{lemma:optimization-problem-part-hdi-vanishers}, the term within parenthesis in \eqref{eq:part-of-proof-use-optimallity-cond} vanishes and we obtain the desired result. Note that \eqref{eq:final-equation-for-normal-component} shows that the derivative exists and is continuous whenever the remaining term is continuous; that is, when $\text{L}_{\mathbf{V}}[\widehat{D}](\mathbf{H},\mathbf{H}_d(s^*))$ is continuous, i.e., when $\mathbf{H} \not \in \mathcal{C} \cup \mathcal{P}$. 
\end{proof}

Now, \eqref{eq:final-equation-for-normal-component} in \cref{lemma:time-derivative-of-distance-function} allows us to define the normal component. 
\begin{definition} [Normal component] \label{def:normal-vector}
    When $\mathbf{H} \not \in \mathcal{C} \cup \mathcal{P}$, the \emph{normal} component of the vector field $\boldsymbol{\xi}_N: G\to\mathbb{R}^m$ is defined as the negative transpose of the term that multiplies $\boldsymbol{\xi}$ in \eqref{eq:final-equation-for-normal-component}, i.e., 
    \begin{align}
        \boldsymbol{\xi}_N(\mathbf{H}) \triangleq -\text{L}_{\mathbf{V}}[\widehat{D}]\Bigl(\mathbf{H}, \mathbf{H}_d(s^*)\Bigr)^{\top}.
    \end{align}
\end{definition}
When $\mathbf{H} \in \mathcal{C} \cup \mathcal{P}$, $\boldsymbol{\xi}_N(\mathbf{H})$ is left undefined. As we will see in \cref{subs:conv-result}, this lack of definition at $\mathcal{C}$ is not an issue, as it will not be necessary to define it in that context. 

Finally, note that the previous definition allows us to express, as in \cref{feat:adriano-time-derivative-lyapunov-normal-comp}, that $\dot{D} = -\boldsymbol{\xi}_N(\mathbf{H})^{\top}\boldsymbol{\xi}$, provided that $\mathbf{H} \not \in \mathcal{C} \cup \mathcal{P}$. In \citet{Rezende2022}, it was possible to write $\dot{D} = \nabla D \boldsymbol{\xi}$, where the gradient is taken with respect to the state, as the system state in that case lies in $\mathbb{R}^m$, which lacks nonlinear manifold constraints. However, our case is more general since the state $\mathbf{H}$ lies on an $m$-dimensional (non-linear, in general) manifold embedded in an Euclidean space with higher dimension $n^2$. Thus, by comparing $\dot{D} = \nabla D \boldsymbol{\xi}$ with $\dot{D} = -\boldsymbol{\xi}_N(\mathbf{H})^{\top}\boldsymbol{\xi}$, we can see that $-\boldsymbol{\xi}_N(\mathbf{H})$ serves as the ``gradient of the distance function'' in this constrained setting.

\begin{example}\label{example:xi_N_rezende}
    Applying \cref{def:normal-vector}, the normal component in \citet{Rezende2022} will be given by
    \begin{align*}
        \boldsymbol{\xi}_{N}(\mathbf{H})= \frac{\mathcal{T}\bigl(\mathbf{H}_d(s^*)\bigr) - \mathcal{T}(\mathbf{H})}{\Bigl\|\mathcal{T}\bigl(\mathbf{H}_d(s^*)\bigr) - \mathcal{T}(\mathbf{H})\Bigr\|},  
    \end{align*}
     i.e., the normalized vector that points from the current point to the nearest point on the curve.
\end{example}
\section{Tangent component}
As in \cref{sec:adriano-review}, the \emph{tangent} component of our vector field is associated solely with the curve. It can be easily defined using \cref{def:XId-twist-Hd-for-tangent}.
\begin{definition} [Tangent component]\label{def:tangent-vector}
     For $\mathbf{H} \not \in \mathcal{P}$, the \emph{tangent} component of the vector field, $\boldsymbol{\xi}_T:G\to\mathbb{R}^m$ is defined as $\boldsymbol{\xi}_T(\mathbf{H})\triangleq\boldsymbol{\xi}_d(s^*(\mathbf{H}))$. 
\end{definition}

\begin{example}
    In \citet{Rezende2022}, the tangent component is precisely the tangent vector of the curve at the nearest point, so $\boldsymbol{\xi}_{T}=\left.\frac{d}{ds}\mathcal{T}(\mathbf{H}_d(s))\right|_{s=s^*}$. However, this is not necessarily true in our more general case. Here, the tangent component represents the generalized twist required at the nearest point $\mathbf{H}_d(s^*)$ on the curve for the system, under the dynamics of \eqref{eq:derivative-H-SL-considered-system}, to move along the curve.
\end{example}
\section{Orthogonality of components}
According to \cref{feat:adriano-orthogonality}, it is necessary that the normal and tangent components of the vector field be orthogonal to each other. This fact is related only to the EC-distance function $D$, consequently to the EE-distance function $\widehat{D}$, and can be achieved through a property of \emph{left-invariance}. We will first define a \emph{left-invariant} distance function and then provide a proposition for the orthogonality condition.
\begin{definition}[Left-invariant distance]\label{def:distance-left-invariant}
    An EE-distance function (\cref{def:distance-D-hat-arbitrary-elements}) $\widehat{D}:G\times G\to\mathbb{R}_+$ is said to be  \emph{left-invariant} if it also satisfies $\widehat{D}(\mathbf{X}\mathbf{V}, \mathbf{X}\mathbf{W}) = \widehat{D}(\mathbf{V}, \mathbf{W})$ for all $\mathbf{V}, \mathbf{W}, \mathbf{X} \in G$ .
\end{definition}
Given this definition, we can state the following:
\begin{proposition}\label{propos:left-invariant-metric-induces-orthogonal}
    Let $\mathbf{H} \not \in \mathcal{C} \cup \mathcal{P}$. If $\widehat{D}$ is a left-invariant distance function (\cref{def:distance-left-invariant}), then the vector field components (\cref{def:normal-vector,def:tangent-vector}) will be orthogonal to each other, i.e., $\boldsymbol{\xi}_N(\mathbf{H})^{\top}\boldsymbol{\xi}_T(\mathbf{H})=0$.
\end{proposition}
\begin{proof}
    Since $\widehat{D}$ is left-invariant, then $\widehat{D}(\mathbf{X}\mathbf{V}, \mathbf{X}\mathbf{W})=\widehat{D}(\mathbf{V}, \mathbf{W})\;\forall\;\mathbf{V}, \mathbf{W}, \mathbf{X}\in G$. Since this holds for any value, take $\mathbf{V}=\mathbf{H}$, $\mathbf{W}=\mathbf{H}_d(s^*)$, and $\mathbf{X}=\exp\bigl(\tau\SL[\boldsymbol{\xi}_T]\bigr)$. Now, due to the left-invariance,
    \begin{align}
    % \begin{split}
        \widehat{D}\Bigl(\exp\bigl(\tau\SL[\boldsymbol{\xi}_T]\bigr)\mathbf{H},\, \exp\bigl(\tau\SL[\boldsymbol{\xi}_T]\bigr)\mathbf{H}_d(s^*)\Bigr)
        =\widehat{D}\bigl(\mathbf{H}, \mathbf{H}_d(s^*)\bigr) \;\forall\;\mathbf{H}\in G,\,\tau\in\mathbb{R}.
    % \end{split}
    \end{align}
    Differentiating both sides of this equation with respect to $\tau$, using \cref{corol:corol1}, and evaluating at $\tau=0$ gives
    \begin{equation}
        \text{L}_{\mathbf{V}}[\widehat{D}]\boldsymbol{\xi}_T {+}\text{L}_{\mathbf{W}}[\widehat{D}]\boldsymbol{\xi}_T= 0, 
    \end{equation}
    in which the dependencies of $\text{L}_{\mathbf{V}}[\widehat{D}], \text{L}_{\mathbf{W}}[\widehat{D}]$ on $\mathbf{H}$ and $\mathbf{H}_d(s^*)$ were omitted. Noting that, by \cref{def:tangent-vector}, $\boldsymbol{\xi}_T = \boldsymbol{\xi}_d(s^*)$, and invoking \cref{lemma:optimization-problem-part-hdi-vanishers}, implies that $\text{L}_{\mathbf{W}}[\widehat{D}]\boldsymbol{\xi}_T = 0$.
    Finally, using \cref{def:normal-vector}, we prove the orthogonality property: $\text{L}_{\mathbf{V}}[\widehat{D}]\boldsymbol{\xi}_T = -\boldsymbol{\xi}_N^{\top}\boldsymbol{\xi}_T=0$ 
\end{proof}
\begin{example}
    In \citet{Rezende2022}, the  EE-distance function $\widehat{D}(\mathbf{V}, \mathbf{W}) = \|\mathcal{T}(\mathbf{V}) - \mathcal{T}(\mathbf{W})\|$ (\cref{ex:adriano-distance-function}) is left-invariant. Note that $\mathcal{T}(\mathbf{X}\mathbf{Y}) = \mathcal{T}(\mathbf{X}) + \mathcal{T}(\mathbf{Y})\;\forall\;\mathbf{X},\mathbf{Y}\in\text{T}(m)$. Let $\mathbf{V}, \mathbf{W}, \mathbf{X} \in \text{T}(m)$, consequently, $\widehat{D}(\mathbf{X}\mathbf{V}, \mathbf{X}\mathbf{W}) = \|\mathcal{T}(\mathbf{X}\mathbf{V}) - \mathcal{T}(\mathbf{X}\mathbf{W})\| = \|\mathcal{T}(\mathbf{X}) + \mathcal{T}(\mathbf{V}) - \mathcal{T}(\mathbf{X}) - \mathcal{T}(\mathbf{W})\| = \widehat{D}(\mathbf{V}, \mathbf{W})$.
\end{example}
\section{Local minima and gradients in distance function}
\cref{feat:adriano-no-local-minima} is the only feature remaining to be present in our formulation. It consists of two parts: the absence of local minima outside the curve, and the fact that the gradient, here represented by its general form $-\boldsymbol{\xi}_N(\mathbf{H})$, never vanishes (whenever it exists).

In order for the EC-distance function to lack local minima outside the curve, we introduce the concept of a \emph{chainable} distance function and then prove that the \emph{chainability} property leads to a distance function without local minima outside the curve. This property requires defining a \emph{path} between elements in a Lie group.
\begin{definition}[Path]\label{def:PHI-path-parameterizer}
    In a Lie group $G$, a \emph{path} $\Phi:[0, 1] \times G \times G \to G$ connecting an element $\mathbf{V}$ to an element $\mathbf{W}$ satisfies the following properties for all $\mathbf{V}, \mathbf{W}\in G,$ and $\sigma\in[0,1]$:
    \begin{property}
        \item $\Phi(\sigma, \mathbf{V}, \mathbf{W})$ is differentiable in $\sigma$;\label{prop:path-continuous}
        \item $\Phi(0, \mathbf{V}, \mathbf{W}) = \mathbf{V},\,\Phi(1, \mathbf{V},\, \mathbf{W}) = \mathbf{W}$.\label{prop:path-initUfinalV}
    \end{property}
\end{definition}

With the definition of a path, we can now define a chainable distance function.
\begin{definition}[Chainable distance]\label{def:chainable-distance}
    A function $\widehat{D}: G \times G \to \mathbb{R}_+$ is called a \emph{chainable} distance if it meets the criteria of an EE-distance function (\cref{def:distance-D-hat-arbitrary-elements}) and satisfies the following property. Specifically, there exists a path $\Phi$ (\cref{def:PHI-path-parameterizer}), such that for any points $\mathbf{V}, \mathbf{W} \in G$ and any $\sigma \in [0,1]$:
    \begin{align*}
        \widehat{D}(\mathbf{V}, \mathbf{W}) = \widehat{D}\bigl(\mathbf{V}, \Phi(\sigma, \mathbf{V}, \mathbf{W})\bigr) + \widehat{D}\bigl(\Phi(\sigma, \mathbf{V}, \mathbf{W}), \mathbf{W} \bigr).
    \end{align*}
\end{definition}

A chainable distance between two elements can be thought of as a chain, such that it can be broken into pieces within the specific path $\Phi$ and render the same result.
\begin{example} \label{ex:chainability}
    The EE-distance function $\widehat{D}(\mathbf{V}, \mathbf{W})=\|\mathcal{T}(\mathbf{V}) - \mathcal{T}(\mathbf{W})\|$ from \citet{Rezende2022} (see \cref{ex:adriano-distance-function}) is also chainable. To demonstrate this, we first define an appropriate path in accordance with \cref{def:PHI-path-parameterizer}. We use $\Phi(\sigma, \mathbf{V}, \mathbf{W})$ so $\mathcal{T}(\Phi(\sigma, \mathbf{V}, \mathbf{W}))$ = $(1 - \sigma)\mathcal{T}(\mathbf{V}) + \sigma \mathcal{T}(\mathbf{W})\;\forall\;\mathbf{V},\mathbf{W}\in \text{T}(m)$ (i.e., a linear path).

    Given the defined path, we show that the EE-distance function $\widehat{D}$ is chainable as follows:
    \begin{align}
        % \begin{split}
            \widehat{D}(\mathbf{V}, \Phi_\sigma) &= \|\mathcal{T}(\mathbf{V}) - (1 - \sigma)\mathcal{T}(\mathbf{V}) - \sigma \mathcal{T}(\mathbf{W})\|
            =\sigma\|\mathcal{T}(\mathbf{V})-\mathcal{T}(\mathbf{W})\|,  \label{eq:example-adriano-chainable-DvPhi}
        % \end{split}
        \\
        % \begin{split}
            \widehat{D}(\Phi_\sigma, \mathbf{W}) &= \|(1 - \sigma)\mathcal{T}(\mathbf{V}) + \sigma \mathcal{T}(\mathbf{W}) - \mathcal{T}(\mathbf{W})\|
            =(1-\sigma)\|\mathcal{T}(\mathbf{V})-\mathcal{T}(\mathbf{W})\|,
        % \end{split}
    \end{align}
    in which $\Phi_{\sigma} = \Phi(\sigma,\mathbf{V},\mathbf{W})$ and the fact that $0\le \sigma \le 1$ was used. Summing both terms and comparing them, the chainability property is evident. 
\end{example}

It will now be proved that the chainability property in \cref{def:chainable-distance} implies the absence of local minima outside the curve in the EC-distance function. This fact will become useful when we prove the convergence to the curve.
\begin{figure}[ht]
    \centering
    \def\svgwidth{.8\linewidth}
    {\small\import{figures/}{liegroup_curve_local_minima.pdf_tex}}
    \caption{Depiction of the proof in \cref{propos:D-NO-local-minima}}
    \label{fig:distance-without-local-minima}
\end{figure}
\begin{proposition}\label{propos:D-NO-local-minima}
    If $\widehat{D}$ is a chainable distance function (\cref{def:chainable-distance}), then it does not have local minima outside the curve $\mathcal{C}$.
\end{proposition}
\begin{proof}
    The proof proceeds by contradiction and is depicted in \cref{fig:distance-without-local-minima}. Take $D$ as an EC-distance function (\cref{def:distance-D-element-curve}) with $\widehat{D}$ being a chainable EE-distance function. Assume that $\mathbf{V}\notin\mathcal{C}$ is a local minimum of $D$ outside the curve, and let $\mathbf{W} \in G$ be (one of) the nearest point(s) on $\mathcal{C}$ to $\mathbf{V}$, i.e., $\mathbf{W}\in\arg\min_{\mathbf{Y}\in\mathcal{C}}\widehat{D}(\mathbf{V}, \mathbf{Y})$.

     Since $\mathbf{V}$ $\not \in \mathcal{C}$ is a local minimum of $D$, there exists a ball $\mathcal{B}_\varepsilon$, with respect to the topology induced by the distance function, of radius $\varepsilon>0$, small enough to not touch the curve, centered at $\mathbf{V}$ such that $D(\mathbf{Y}) \ge D(\mathbf{V})\; \forall\; \mathbf{Y} \in \mathcal{B}_\varepsilon$. Given that a path $\Phi$ between $\mathbf{V}$ and $\mathbf{W}$ is continuous (see \cref{def:PHI-path-parameterizer}), there must exist $\sigma_0 \in (0,1)$ such that a point $\mathbf{X}=\Phi(\sigma_0, \mathbf{V}, \mathbf{W})$ lies in the intersection of the boundary of the ball $\partial\mathcal{B}_\varepsilon$ and the path. According to our assumption, $D(\mathbf{V}) \le D(\mathbf{X})$, where $D(\mathbf{X}) = \min_{\mathbf{Y}\in\mathcal{C}} \widehat{D}(\mathbf{X}, \mathbf{Y})$. Now, since $D(\mathbf{X})$ is the minimum EE-distance between $\mathbf{X}$ and the curve, it must be true that this distance is less than or equal to the EE-distance between $\mathbf{X}$ and $\mathbf{W}$, i.e., $D(\mathbf{X})\le \widehat{D}(\mathbf{X}, \mathbf{W})$. The results until now allows us to obtain the following:
     \begin{align}
         D(\mathbf{V}) \le D(\mathbf{X}) \le \widehat{D}(\mathbf{X}, \mathbf{W}). \label{eq:lemma-local-minima-contradiction-eq1}
     \end{align}
    In addition, by the chainability property (see \cref{def:chainable-distance}), we also have $D(\mathbf{V}) \ge \widehat{D}(\Phi(\sigma, \mathbf{V}, \mathbf{W}), \mathbf{W})\;\forall\;\sigma\in[0,1]$. Since this holds for any value of $\sigma$, take $\sigma=\sigma_0$, which results in 
    \begin{align}
        D(\mathbf{V}) \ge \widehat{D}(\mathbf{X}, \mathbf{W}). \label{eq:lemma-local-minima-contradiction-eq2}
    \end{align}
    We now force a contradiction. Since conditions \eqref{eq:lemma-local-minima-contradiction-eq1} and \eqref{eq:lemma-local-minima-contradiction-eq2} must hold simultaneously, it follows that $D(\mathbf{V}) = \widehat{D}(\mathbf{X}, \mathbf{W})$. But, from the chainability property (see \cref{def:chainable-distance}), we know that $D(\mathbf{V}) = \widehat{D}(\mathbf{V}, \mathbf{W}) = \widehat{D}(\mathbf{V}, \mathbf{X}) + \widehat{D}(\mathbf{X}, \mathbf{W})$. This implies that $\widehat{D}(\mathbf{V}, \mathbf{X})=0$, therefore, since $\widehat{D}$ is positive definite, it follows that $\mathbf{V}=\mathbf{X}$, contradicting the existence of such a ball $\mathcal{B}_\varepsilon$. 
\end{proof}

We now establish that, under certain mild conditions, $-\boldsymbol{\xi}_N(\mathbf{H})$, which plays the role of the gradient of the distance in our case, never vanishes wherever it is defined. This result is evident in \citet{Rezende2022}, as demonstrated in \cref{example:xi_N_rezende}. The necessary ``mild'' condition for establishing this is as follows.

\begin{definition} [Locally linear] \label{def:locallylinear}
    A chainable EE-distance $\widehat{D}$ is said to be \emph{locally linear} if, for any $\mathbf{V}, \mathbf{W} \in G$, $\mathbf{V} \not = \mathbf{W}$:
    \begin{equation}
        \lim_{\sigma \rightarrow 0^+} \frac{1}{\sigma} \widehat{D}\bigl(\mathbf{V},\Phi(\sigma,\mathbf{V},\mathbf{W})\bigr) > 0.
    \end{equation}
\end{definition}
The name arises from the fact that, for any $\mathbf{V} \not= \mathbf{W}$, $\widehat{D}\bigl(\mathbf{V},\Phi(\sigma,\mathbf{V},\mathbf{W})\bigr) \approx o(\sigma)$ (i.e., it is approximately linear in the small ``$o$'' notation).

\begin{example}
    Let $\widehat{D}$ be the EE-distance as in \cref{ex:adriano-distance-function} and $\Phi$ the path in \cref{ex:chainability}. From \eqref{eq:example-adriano-chainable-DvPhi}, we know that $\widehat{D}(\mathbf{V}, \Phi(\sigma, \mathbf{V}, \mathbf{W})) = \sigma\|\mathcal{T}(\mathbf{V}) - \mathcal{T}(\mathbf{W})\|$, thus $\lim_{\sigma \to 0^+} \frac{1}{\sigma} \widehat{D}\bigl(\mathbf{V},\Phi(\sigma,\mathbf{V},\mathbf{W})\bigr) = \lim_{\sigma \to 0^+} \frac{1}{\sigma}\sigma\|\mathcal{T}(\mathbf{V}) - \mathcal{T}(\mathbf{W})\| = \|\mathcal{T}(\mathbf{V}) - \mathcal{T}(\mathbf{W})\| > 0$ for $\mathbf{V} \not= \mathbf{W}$, and thus $\widehat{D}$ is locally linear.
\end{example}

\begin{lemma} \label{lemma:no-zero-xiN} If $\widehat{D}$ is chainable (\cref{def:chainable-distance}) and locally linear (\cref{def:locallylinear}), for any $\mathbf{H} \notin \mathcal{C} \cup \mathcal{P}$, $\boldsymbol{\xi}_N(\mathbf{H}) \not= \mathbf{0}$.
\end{lemma}

\begin{proof}
    Let $\mathbf{H} \notin \mathcal{C} \cup \mathcal{P}$. Choosing $\mathbf{V} = \mathbf{H}$, $\mathbf{W} = \mathbf{H}_d(s^*) = \mathbf{H}^*$, and using the property of chainable functions:
    \begin{align}        
        \begin{split}
            & D(\mathbf{H}) = \widehat{D}(\mathbf{H},\mathbf{H}^*) = \widehat{D}\bigl(\mathbf{H},\Phi(\sigma,\mathbf{H},\mathbf{H}^*)\bigr){+} \widehat{D}\bigl(\Phi(\sigma,\mathbf{H},\mathbf{H}^*),\mathbf{H}^*\bigr).        
        \end{split}
    \end{align}
Now, $\widehat{D}\bigl(\Phi(\sigma,\mathbf{H},\mathbf{H}^*),\mathbf{H}^*\bigr) \geq D\bigl(\Phi(\sigma,\mathbf{H},\mathbf{H}^*)\bigr)$. Thus:
\begin{align}
    D(\mathbf{H})-D\bigl(\Phi(\sigma,\mathbf{H},\mathbf{H}^*)\bigr) \geq \widehat{D}\bigl(\mathbf{H},\Phi(\sigma,\mathbf{H},\mathbf{H}^*)\bigr).
\end{align}
Divide both sides by $\sigma >0$ and take the limit as $\sigma \rightarrow 0^+$. Since $\mathbf{H} \not \in \mathcal{C}$, $\mathbf{H} \not = \mathbf{H}^*$, and, using \cref{def:locallylinear}:
\begin{align}
\label{eq:impineq}
 \lim_{\sigma \rightarrow 0^+} \frac{D(\mathbf{H})-D\bigl(\Phi(\sigma,\mathbf{H},\mathbf{H}^*)\bigr)}{\sigma} > 0.   
\end{align}
Let $\boldsymbol{\xi}_\Phi(\sigma,\mathbf{H}) \triangleq \Xi[\Phi](\sigma,\mathbf{H})$. Then, from \cref{lemma:very-important-fact}, it is true that $\Phi(\sigma,\mathbf{H},\mathbf{H}^*) \approx \exp(\SL[\boldsymbol{\xi}_\Phi]\sigma)\mathbf{H}$ for $\sigma \approx 0$. Consequently, the left-hand side of \eqref{eq:impineq} can be written as:
\begin{equation}
\label{eq:impineq2}
  -\lim_{\sigma \rightarrow 0^+} \left( \frac{D\bigl(\exp(\SL[\boldsymbol{\xi}_\Phi]\sigma)\mathbf{H}\bigr) - D(\mathbf{H})}{\sigma} \right).
\end{equation}
Using \cref{def:Loperator}, this last limit, whenever it exists, is exactly $-\text{L}[D](\mathbf{H}) \boldsymbol{\xi}_\Phi$. This limit exists when $\mathbf{H} \not \in \mathcal{C} \cup \mathcal{P}$. But, from \cref{lemma:time-derivative-of-distance-function} and \cref{def:normal-vector}, it can be seen that this limit is also $\boldsymbol{\xi}_N(\mathbf{H})^\top \boldsymbol{\xi}_\Phi$. Thus, from  \eqref{eq:impineq}, $\boldsymbol{\xi}_N(\mathbf{H})^\top \boldsymbol{\xi}_\Phi > 0$,  which implies that $\boldsymbol{\xi}_N(\mathbf{H}) \not= \mathbf{0}$. 
\end{proof}
Intuitively, this lemma means that from any point $\mathbf{H} \notin \mathcal{C} \cup \mathcal{P}$ we can always move in the direction of the closest point $\mathbf{H}^*$ along the path $\Phi$ by applying the twist $\boldsymbol{\xi}_\Phi$ in \eqref{eq:derivative-H-SL-considered-system}. This motion decreases $D$ sufficiently to ensure that the derivative does not vanish, which means that $\boldsymbol{\xi}_N(\mathbf{H})$ cannot be zero, since $\dot{D} = -\boldsymbol{\xi}_N(\mathbf{H})^{\top} \boldsymbol{\xi}$ for any arbitrary twist $\boldsymbol{\xi}$ (\cref{lemma:time-derivative-of-distance-function}).
\section{Convergence results}
\label{subs:conv-result}
With the established definitions, lemmas, and propositions, we can now prove the main result of this text. To do so, we first require the following lemma.

\begin{lemma} \label{lemma:xiNvanishing} If $\widehat{D}$ is an EE-distance function (\cref{def:distance-D-hat-arbitrary-elements}), then 
    \begin{align}
        \lim_{\mathbf{H} \rightarrow \mathcal{C}} k_N(\mathbf{H}) \boldsymbol{\xi}_N(\mathbf{H}) = \mathbf{0}.
    \end{align}
\end{lemma}
\begin{proof}
    From \cref{def:normal-vector}, when $\mathbf{H} \rightarrow \mathcal{C}$, the quantity $\text{L}_{\mathbf{V}}[\widehat{D}](\mathbf{V},\mathbf{W})$ is evaluated when $\mathbf{V} = \mathbf{W}$ (i.e., $\mathbf{H} = \mathbf{H}_d(s^*)$). According to \cref{def:distance-D-hat-arbitrary-elements}, this derivative does not necessarily exist, but all directional limit should exist and be bounded. Since $k_N(\mathbf{H}) = 0$ when $\mathbf{H} \rightarrow \mathcal{C}$, this concludes the result. 
\end{proof}
This lemma shows that the vector field in \eqref{eq:vector-field-proposition} remains well-defined when $\mathbf{H} \in \mathcal{C}$, even though $\boldsymbol{\xi}_N(\mathbf{H})$ is undefined at these points. Now, we present our theorem:
\begin{theorem}\label{thm:convergence-vector-field}
    Let $\widehat{D}$ be a \emph{left-invariant} (\cref{def:distance-left-invariant}) , \emph{chainable} (\cref{def:chainable-distance}) and \emph{locally linear} (\cref{def:locallylinear}) EE-distance function, and $\mathbf{H}_d(s)$ a proper (\cref{def:XId-twist-Hd-for-tangent}) parametrization for $\mathcal{C}$. Then, the closed loop autonomous dynamical system in  \eqref{eq:derivative-H-SL-considered-system}, with the input given by  \eqref{eq:vector-field-proposition}, is such that 
    \begin{enumerate}[label=(\roman*)]
        \item the system's state converges either to $\mathcal{C}$ or $\mathcal{P}$;
        \item the set $\mathcal{P}$ is ``escapable'': there exists a policy of choosing arbitrarily small $\boldsymbol{\xi}$ every time $\mathbf{H} \in \mathcal{P}$ such that there exists a finite $t'$ in which $\mathbf{H}(t) \not \in \mathcal{P}$ for all $t \geq t'$;
        \item if the system's state converges to  $\mathcal{C}$, $\mathbf{H}$ circulates the target curve.
    \end{enumerate}
\end{theorem}
\begin{proof}
    \textbf{Statement (i):} Consider $D$ as in \cref{def:distance-D-element-curve} as a Lyapunov function candidate. According to \cref{lemma:time-derivative-of-distance-function} and \cref{def:normal-vector}, its derivative is given by $\dot{D} = -\boldsymbol{\xi}_N^{\top}\boldsymbol{\xi} $ for any $\mathbf{H} \notin \mathcal{C} \cup \mathcal{P}$. Substituting $\boldsymbol{\xi}=\Psi=k_N\boldsymbol{\xi}_N+k_T\boldsymbol{\xi}_T$ and using \cref{propos:left-invariant-metric-induces-orthogonal}, we obtain 
\begin{align}
\label{eq:Ddotnegative}
    \frac{d}{dt}D(\mathbf{H})= -k_N(\mathbf{H})\|\boldsymbol{\xi}_N(\mathbf{H})\|^2 \;\forall\;\mathbf{H} \notin \mathcal{C} \cup \mathcal{P}
\end{align}
Note, however, that \cref{lemma:xiNvanishing} guarantees that $\dot{D}$ will also vanish when $\mathbf{H} \in \mathcal{C}$. This fact, along with \eqref{eq:Ddotnegative} and \cref{lemma:no-zero-xiN}, shows that $\dot{D} < 0$ for all $\mathbf{H} \not \in \mathcal{C} \cup \mathcal{P}$, $\dot{D} = 0$ for $\mathbf{H} \in \mathcal{C}$, and $D$ is non-differentiable when $\mathbf{H} \in \mathcal{P}$. This shows that the system either converges to $\mathcal{C}$ or $\mathcal{P}$.

\textbf{Statement (ii):} \cref{propos:D-NO-local-minima} shows that $D$ will not have any local minima outside $\mathcal{C}$. Thus, for each $\mathbf{H} \in \mathcal{P}$, there exists an arbitrarily small perturbation twist $\boldsymbol{\xi}_P(\mathbf{H})$ \footnote{To be more precise, \cref{propos:D-NO-local-minima} shows that one such twist is one that moves $\mathbf{H}$ in the direction of any of the possible $\mathbf{H}_d(s^*)$ through the path induced by $\Phi$.} such that the perturbed state $\mathbf{H}'$ satisfies $D(\mathbf{H}') < D(\mathbf{H})$. Furthermore, there is a non-zero minimum decrease $\delta$ that can be obtained at all steps. Let $t_k$ be the time at which $\mathbf{H}(t)$ enters $\mathcal{P}$ for the $k^{th}$ time, under the application of the controller and the corresponding perturbation policy. Then, we have $D(\mathbf{H}(t_{k+1})) < D(\mathbf{H}(t_k))$, with a decrease of at least $\delta$ at each step. Let $D_{\text{min}, \mathcal{P}} \triangleq \min_{\mathbf{H} \in \mathcal{P}} D(\mathbf{H})$, which is positive since $\mathcal{C} \cap \mathcal{P} = \emptyset$ and $D_{\text{min},\mathcal{C}}$ in \cref{def:distance-D-hat-arbitrary-elements} is strictly positive. The decreasing sequence $D(t_k)$ must eventually fall below $D_{\text{min}, \mathcal{P}}$ for some finite $k$. From that point onward, since $\dot{D} \leq 0$, $\mathcal{P}$ will not be re-entered.

\textbf{Statement (iii):} Circulation comes from the fact that, once in $\mathcal{C}$, the term $k_N \boldsymbol{\xi}_N$ vanishes (\cref{lemma:xiNvanishing}), while $k_T \boldsymbol{\xi}_T$---the necessary twist to track the curve in a given sense (clockwise or counter-clockwise)---remains non-zero. This non-zero value, due to $k_T$ being positive and that $\mathbf{H}_d$ being a proper parametrization (see \cref{def:XId-twist-Hd-for-tangent}), enforces the circulation of the curve.
\end{proof} 
Note that the sense of circulation (clockwise or counterclockwise) is determined by the choice of parametrization $\mathbf{H}_d(s)$. For instance, using the reparametrization $\mathbf{H}_{d,\text{new}}(s) = \mathbf{H}_d(1-s)$ results in circulation in the opposite direction.

Result (ii) in \cref{thm:convergence-vector-field} implies that if the system enters the ``problematic set'' $\mathcal{P}$, there always exists an arbitrarily small sequence of maneuvers that enables the system to eventually escape this set in finite time and never return. Furthermore, as a corollary of \cref{thm:convergence-vector-field}, we can interpret that the closed loop system is asymptotically stable to the desired curve if $D(\mathbf{H}(0)) < D_{\text{min}, \mathcal{P}}$. In other words, starting sufficiently close to the target curve ensures that $\mathcal{P}$ is never reached.
\section{Explicit construction for exponential Lie groups}\label{sec:kinematic-path-ee-dist-exp-group} % \label{subs:explconst}
While our results are valid for any connected matrix Lie group, we now provide explicit computations for exponential Lie groups (see \cref{sec:background-exponential-map}), leveraging the surjectivity of the exponential map. In order to define the path and the EE-distance function, we first introduce some properties of the logarithm.
% \section{Path and EE-distance function for exponential Lie groups}

For exponential Lie groups, while the exponential map is surjective, it is not necessarily bijective. However, we can define an inverse function in the following manner. Let $\mathbb{R}_+^{n\times n}$ be the set of real matrices with no negative real eigenvalues. Additionally, let $\mathcal{L}^n$ represent the set of $n\times n$ real matrices whose eigenvalues $\lambda$ lie within the strip $\{\lambda : -\pi < \text{Im}(\lambda) < \pi\}$. The function $\exp:\mathcal{L}^n\to\mathbb{R}_+^{n\times n}$ is bijective, ensuring the existence of an inverse function $\Log: \mathbb{R}_+^{n\times n} \to \mathcal{L}^n$, referred to as the \emph{principal logarithm} \citep[p. 320]{Gallier2020}. Furthermore, let $\mathcal{L}_{\mathfrak{g}}^n\subseteq\mathfrak{g}$ be the subset of $n \times n$ real matrices---elements of the Lie algebra-- whose eigenvalues $\lambda$ lie in the strip $\{\lambda : -\pi \le \text{Im}(\lambda) \le \pi\}$. We define the logarithm function $\log:G\to\mathcal{L}_{\mathfrak{g}}^n$ such that $\log(\mathbf{Z})$ coincides with $\Log(\mathbf{Z})$ when $\mathbf{Z}\in\mathbb{R}_+^{n\times n}$, and otherwise corresponds to some specific matrix $\mathbf{Y}\in\mathcal{L}_{\mathfrak{g}}^n$ that satisfies $\exp(\mathbf{Y}) = \mathbf{Z}$. This is feasible because we assume the group is exponential. Moreover, this choice should be predefined and deterministic.

With this, we can state the following important lemma.
\begin{lemma}\label{lemma:log-exp-log-equals-log}
    For all $\mathbf{Z}\in G$ and for all $r \in[0, 1]$, the following property holds:
    \begin{align*}
        \log\Bigl(\exp\bigl(r\log(\mathbf{Z})\bigr)\Bigr) = r\log(\mathbf{Z})
    \end{align*}
\end{lemma}
\begin{proof}
    The proof will be divided in three cases.
    
    \textbf{Case 1:} When $\mathbf{Z} \in \mathbb{R}_+^{n\times n}$ and $r\in[0,1]$, $\log(\mathbf{Z})=\Log(\mathbf{Z})$ and therefore $\log(\mathbf{Z})$ will lie on $\mathcal{L}^n$. Since $0\le r\le1$, then\footnote{Note that if $\lambda$ is an eigenvalue of $\mathbf{X}$, then $r\lambda$ is an eigenvalue of $r\mathbf{X}$ for any scalar $r$.} it holds that $r \log(\mathbf{Z})$ will also lie on $\mathcal{L}^n$. Moreover, since in this case, the logarithm is equal to the principal logarithm, which is invertible within its domain, it holds by definition that $\log\Bigl(\exp\bigl(r\log(\mathbf{Z})\bigr)\Bigr) = r\log(\mathbf{Z})$.

    \textbf{Case 2:} Now, let $\mathbf{Z}\notin \mathbb{R}_+^{n\times n}$ and $r\in[0, 1)$, then $\log(\mathbf{Z}) \in \mathcal{L}^n_\mathfrak{g}$. Thus $r\log(\mathbf{Z})\in\mathcal{L}^n$, where the logarithm is bijective. Therefore, the expression also holds.

    \textbf{Case 3:} Now, let $\mathbf{Z}\notin \mathbb{R}_+^{n\times n}$ and $r=1$. In this case, the expression reduces to $\log(\exp(\log(\mathbf{Z}))) = \log(\mathbf{Z})$. By the definition of $\log$, it follows that $\exp(\log(\mathbf{Z})) = \mathbf{Z}$, which ensures that the equality holds since the $\log$ function is predefined and deterministic.
\end{proof}

% \subsection{Path and EE-distance function}
For the exponential Lie groups, a path $\Phi_\sigma\triangleq\Phi(\sigma, \mathbf{V}, \mathbf{W})$ can be defined as:
\begin{align}
    \Phi(\sigma, \mathbf{V}, \mathbf{W}) = \mathbf{V}\exp{\left(\log{\left(\mathbf{V}^{-1}\mathbf{W}\right)}\sigma\right)}, \label{eq:PHI-path-parameterizer-utilized-exp-of-log}
\end{align}
which is in accordance with \cref{def:PHI-path-parameterizer}. Then, an EE-distance function is defined as:
\begin{align}
    \widehat{D}(\mathbf{V}, \mathbf{W}) = \|\log{(\mathbf{V}^{-1}\mathbf{W})}\|_F.\label{eq:distance-D-hat-utilized-log-norm}
\end{align}

\begin{remark}
    The path \eqref{eq:PHI-path-parameterizer-utilized-exp-of-log} and EE-distance \eqref{eq:distance-D-hat-utilized-log-norm} reduce to the ones in \cref{ex:chainability} and \cref{ex:adriano-distance-function}, respectively, when applied to the particular case $G=\text{T}(m)$.

    Let $\mathcal{T}(\mathbf{V}) = \mathbf{v}\in\mathbb{R}^m$, $\mathcal{T}(\mathbf{W}) = \mathbf{w}\in\mathbb{R}^m$. Using the series expansion of $\log$ and $\exp$, we find that
    \begin{align}
    \begin{split}
        \mathbf{V}\exp{\bigl(\log{(\mathbf{V}^{-1}\mathbf{W})}\sigma\bigr)} 
        = \begin{bmatrix}
            \mathbf{I} & (1 - \sigma)\mathbf{v} + \sigma \mathbf{w}\\ \mathbf{0} & 1
        \end{bmatrix}.
        \end{split}
    \end{align}
    Note that $\mathcal{T}\bigl((1 - \sigma)\mathbf{V} + \sigma\mathbf{W}\bigr) = (1 - \sigma)\mathcal{T}(\mathbf{V}) + \sigma \mathcal{T}(\mathbf{W})$, the path in \cref{ex:chainability}.

    Using the series expansion of $\log$ again, $\|\log{(\mathbf{V}^{-1}\mathbf{W})}\|_F$
    $= \|\mathbf{V}^{-1}\mathbf{W} - \mathbf{I}\|_F$. Note that $\mathbf{V}^{-1}\mathbf{W} - \mathbf{I}$ is a matrix whose only non-zero column is the last one, equal to $[\,(\mathbf{w} - \mathbf{v})^\top\quad 0\,]^\top$, this implies that $\|\mathbf{V}^{-1}\mathbf{W} - \mathbf{I}\|_F$$=\|\mathbf{w}-\mathbf{v}\|$, which is clearly equal to the EE-distance in \cref{ex:adriano-distance-function}. 
\end{remark}

In order to invoke \cref{thm:convergence-vector-field}, function $\widehat{D}$ in \eqref{eq:distance-D-hat-utilized-log-norm} needs to be an EE-distance (see \cref{def:distance-D-hat-arbitrary-elements}) that is left-invariant (see \cref{def:distance-left-invariant}), chainable (see \cref{def:chainable-distance}) and locally linear (see \cref{def:locallylinear}). Thus, we prove all of these properties in the following proposition.

\begin{proposition}
    Adopting the path $\Phi$ in \eqref{eq:PHI-path-parameterizer-utilized-exp-of-log}, the function $\widehat{D}$ in \eqref{eq:distance-D-hat-utilized-log-norm} is a left-invariant, chainable, and locally linear EE-distance.
\end{proposition}
\begin{proof}
    We prove each property separately. 
    
    \textbf{EE-distance}: Positive definiteness and differentiability are immediate upon inspection, and thus $\widehat{D}$ is an EE-distance.
    
    \textbf{Left-invariant}: The distance function is left-invariant since, for all $\mathbf{X} \in G$, we have $\widehat{D}(\mathbf{X}\mathbf{V}, \mathbf{X}\mathbf{W}) =  \|\log{(\mathbf{V}^{-1}\mathbf{X}^{-1}\mathbf{X}\mathbf{W})}\|_F$, which is clearly equal to $\widehat{D}(\mathbf{V}, \mathbf{W})$.

    \textbf{Chainable}: To prove the chainability property, we first substitute $\Phi$ by its expression \eqref{eq:PHI-path-parameterizer-utilized-exp-of-log} in \eqref{eq:distance-D-hat-utilized-log-norm}, which results in
    \begin{align}
        % \begin{split}
             \widehat{D}(\mathbf{V}, \Phi_\sigma) &= \Bigl\|\log\Bigl(\mathbf{V}^{-1}\mathbf{V}\exp\bigl(\log(\mathbf{V}^{-1}\mathbf{W})\sigma\bigr)\Bigr)\Bigr\|_F
             =\sigma\Bigl\|\log{\left(\mathbf{V}^{-1}\mathbf{W}\right)}\Bigr\|_F,
        % \end{split}
    \end{align}
    using \cref{lemma:log-exp-log-equals-log} with $\mathbf{Z}=\mathbf{V}^{-1}\mathbf{W}$ and $r=\sigma$, and the fact that $\sigma\ge0$. Now, using the fact that, by definition, $\mathbf{V}^{-1}\mathbf{W}=\exp(\log(\mathbf{V}^{-1}\mathbf{W}))$, we can express the following:
    \begin{align}
             \widehat{D}(\Phi_\sigma, \mathbf{W}) = \Bigl\|\log\Bigl(\exp\bigl(-\log(\mathbf{V}^{-1}\mathbf{W})\sigma\bigr)\exp\bigl(\log(\mathbf{V}^{-1}\mathbf{W})\bigr)\Bigr)\Bigr\|_F
    \end{align}
    Note that $\log(\mathbf{V}^{-1}\mathbf{W})$ commutes with $-\sigma\log(\mathbf{V}^{-1}\mathbf{W})$, and thus we can express the product of exponentials as the exponential of the sum of the arguments:
    \begin{align}
        \widehat{D}(\Phi_\sigma, \mathbf{W}) = \Bigl\|\log\Bigl(\exp\bigl((1-\sigma)\log(\mathbf{V}^{-1}\mathbf{W})\bigr)\Bigr)\Bigr\|_F.
    \end{align}
    Invoking \cref{lemma:log-exp-log-equals-log} with $\mathbf{Z}=\mathbf{V}^{-1}\mathbf{W}$ and $r=1-\sigma$, and using the fact that $0\le\sigma\le1$, the previous expression reduces to 
    \begin{align}
       \widehat{D}(\Phi_\sigma, \mathbf{W}) =(1-\sigma)\|\log{\left(\mathbf{V}^{-1}\mathbf{W}\right)}\|_F.
    \end{align}
    Clearly, $\widehat{D}(\mathbf{V}, \Phi_\sigma) + \widehat{D}(\Phi_\sigma, \mathbf{W}) = \|\log(\mathbf{V}^{-1}\mathbf{W})\|_F = \widehat{D}(\mathbf{V}, \mathbf{W})$. 
    
    \textbf{Locally linear}: to prove that $\widehat{D}$ is locally linear, first note that, using \cref{lemma:log-exp-log-equals-log} and the fact that $\sigma$ is non-negative, $\widehat{D}(\mathbf{V}, \Phi_\sigma) = \sigma\|\log{\left(\mathbf{V}^{-1}\mathbf{W}\right)}\|_F$, thus we have
    \begin{align}
        % \begin{split}
            \lim_{\sigma\to0^+}\frac{1}{\sigma}\widehat{D}(\mathbf{V}, \Phi_\sigma) &= \lim_{\sigma\to0^+}\frac{\sigma}{\sigma}\|\log{(\mathbf{V}^{-1}\mathbf{W})}\|_F
            = \|\log{(\mathbf{V}^{-1}\mathbf{W})}\|_F > 0
        % \end{split}
    \end{align}
    as long as $\mathbf{V} \not= \mathbf{W}$.
\end{proof}

\subsection{The particular case of SE(3)}\label{sec:explicit-construction-SE3}
As mentioned, the group \text{SE}(3) is exponential, allowing us to use the construction from \cref{sec:kinematic-path-ee-dist-exp-group}. However, instead of computing $\widehat{D}(\mathbf{V},\mathbf{W}) = \|\log(\mathbf{V}^{-1}\mathbf{W})\|_F$ through a generic algorithm to compute the matrix logarithm followed by applying the Frobenius norm, the structure of the group $\text{SE}(3)$ allows a more efficient and simpler approach. The algorithm for computing $\widehat{D}(\mathbf{V},\mathbf{W})$ is as follows:

Let $\mathbf{R}_v$, $\mathbf{R}_w$, $\mathbf{p}_v$, and $\mathbf{p}_w$ denote the rotation matrices and positions of $\mathbf{V}$ and $\mathbf{W}$, respectively. Let $\mathbf{V}^{-1}\mathbf{W} = \mathbf{Z}$, and express it as 
\begin{align*}
    \mathbf{V}^{-1}\mathbf{W} = \mathbf{Z} =\begin{bmatrix}
        \mathbf{R}_v^\top\mathbf{R}_w & \mathbf{R}_v^\top(\mathbf{p}_w - \mathbf{p}_v) \\
        \mathbf{0} & 1
    \end{bmatrix}
    = \begin{bmatrix}
        \mathbf{Q} & \mathbf{u} \\
        \mathbf{0} & 1
    \end{bmatrix}.
\end{align*}

From \citet[p. 41]{Gallier2020}, the logarithm of a homogeneous transformation matrix $\mathbf{Z}$ can be expressed as
\begin{align}
    \log\mathbf{Z} &= \begin{bmatrix}
        \log\mathbf{Q} & \mathbf{X}\mathbf{u}\\\mathbf{0} & \mathbf{0}
    \end{bmatrix},
\end{align}
where $\mathbf{X} = (\mathbf{I} - \mathbf{Q})^{-1}\log(\mathbf{Q})$ with some abuse of notation. With this, we can express the EE-distance as
\begin{align}
    \begin{split}
    \widehat{D}(\mathbf{V}, \mathbf{W}) &= \|\log\mathbf{Z}\|_F = \tr\left(
        \begin{bmatrix}
            (\log\mathbf{Q})^\top\log\mathbf{Q} & (\log\mathbf{Q})^\top\mathbf{X}\mathbf{u}\\
            \mathbf{u}^\top\mathbf{X}^\top\log\mathbf{Q} & \mathbf{u}^\top\mathbf{X}^\top\mathbf{X}\mathbf{u}
        \end{bmatrix}
    \right)^\frac{1}{2}\\
        &= \sqrt{\|\log\mathbf{Q}\|_F^2 + \mathbf{u}^\top\mathbf{X}^\top\mathbf{X}\mathbf{u}} = \sqrt{\|\log\mathbf{Q}\|_F^2 + \|\bar{\mathbf{u}}\|^2},
    \end{split}
\end{align}
where $\|\bar{\mathbf{u}}\|^2 = \mathbf{u}^\top\bar{\mathbf{X}}\mathbf{u}$ and $\bar{\mathbf{X}}=\mathbf{X}^\top\mathbf{X}$.

The term $\|\log\mathbf{Q}\|_F^2$ can be obtained by the following steps, using the properties derived in \cref{subsec:rotation-matrix-properties}:
\begin{enumerate}
    \item Compute $u \triangleq \frac{1}{2}\bigl(\tr(\mathbf{Q})-1\bigr)$ and $v \triangleq \frac{1}{2\sqrt{2}}\|\mathbf{Q}{-}\mathbf{Q}^{\top}\|_F$, where $u = \cos(\theta)$ and $v=\sin(\theta)$, in which $\theta \in [0, \pi]$ is the rotation angle related to $\mathbf{Q}$;
    \item Compute $\theta = \text{atan2}(v,u)$;
    \item Then, $\|\log\mathbf{Q}\|_F^2 = 2\theta^2$.
\end{enumerate}

It is also possible to derive a simple expression for $\|\bar{\mathbf{u}}\|^2$. First, we express $\bar{\mathbf{X}}$ as a function $\Phi(\mathbf{Q})$ using the Cayley-Hamilton theorem \citep[p. 63]{Chen2009}. The derivation of this function is presented in \cref{app:translation-component-SE3} and the resulting expression is:
\begin{align}
    \Phi(\mathbf{Q}) = \bar{\mathbf{X}} = (1-2\beta_0)\mathbf{I} + \beta_0\bigl(\mathbf{Q} + \mathbf{Q}^\top\bigr), \label{eq:explicit-X-bar-eedist}
\end{align}
where $\beta_0=\frac{2-2\cos\theta-\theta^2}{4(1 - \cos\theta)^2}$. Thus $\|\bar{\mathbf{u}}\|^2$ can be easily obtained from the already computed angle $\theta$ and the translation vector $\mathbf{u}$. The EE-distance function reduces to
\begin{align}
    \widehat{D}(\mathbf{V}, \mathbf{W}) = \sqrt{2\theta^2 + \mathbf{u}^\top\bar{\mathbf{X}}\mathbf{u}}, \label{eq:explicit-EE-distance-SE3}
\end{align}
where $\bar{\mathbf{X}}$ is explicitly computed by \eqref{eq:explicit-X-bar-eedist}. More succinctly, the algorithm for computing $\widehat{D}(\mathbf{V}, \mathbf{W})$ is shown in \cref{alg:dhat-se3}.
\begin{algorithm}
    \caption{Computation of $\widehat{D}(\mathbf{V}, \mathbf{W})$ in $\text{SE}(3)$}
    \label{alg:dhat-se3}
    \begin{algorithmic}[1]
        \Statex \textbf{Input:} Matrices $\mathbf{V}, \mathbf{W}$
        \Statex \textbf{Output:} Distance $\widehat{D}$
        % \Statex
        
        \State Compute $\mathbf{Z} \gets \mathbf{V}^{-1}\mathbf{W}$
        \State Extract $\mathbf{Q} \gets \text{rotation part of } \mathbf{Z}$ and $\mathbf{u} \gets \text{translation part of } \mathbf{Z}$

        \State $u \gets \frac{1}{2} (\tr(\mathbf{Q}) - 1)$
        \State $v \gets \frac{1}{2\sqrt{2}} \|\mathbf{Q} - \mathbf{Q}^\top\|_F$
        \State $\theta \gets \text{atan2}(v, u)$

        \State $\beta_0 \gets \frac{2 - 2u - \theta^2}{4(1 - u)^2}$
        \State $\bar{\mathbf{X}} \gets \mathbf{I}(1 - 2\beta_0) + (\mathbf{Q} + \mathbf{Q}^\top)\beta_0$

        \State $\widehat{D} \gets \sqrt{2\theta^2 + \mathbf{u}^\top \bar{\mathbf{X}} \mathbf{u}}$
    \end{algorithmic}
\end{algorithm}

It can be shown that the result of $\|\log(\mathbf{V}^{-1}\mathbf{W})\|_F$ is independent of the choice of $\log(\mathbf{V}^{-1}\mathbf{W})$ in the edge cases where $\mathbf{V}^{-1}\mathbf{W}$ has negative eigenvalues (see the discussion in \cref{sec:kinematic-path-ee-dist-exp-group}). This is evident in the fact that \cref{alg:dhat-se3} does not include any components that require a choice to be made.

Note that $\beta_0$ is well-defined for all $\theta \in (0,\pi]$. When $\theta=0$, we just need to take the limit to obtain $\beta_0=-1/12$ (see \cref{app:discontinuity-beta-EEdist}). To identify the points of non-differentiability of $\widehat{D}$, it suffices to analyze the derivatives with the respect to the variables $\mathbf{Q}$ and $\mathbf{u}$. The analysis reveals that the only sources of non-differentiability occur when (type i) $\mathbf{Q}=\mathbf{Q}^\top$, $\mathbf{Q} \not= \mathbf{I}$ (i.e., at rotations of $\pi$ radians) or when (type ii) $\widehat{D}=0$. However, in both cases, the directional derivatives exist. Furthermore, $D_{\text{min},\mathcal{C}}$, as defined in \cref{def:distance-D-hat-arbitrary-elements}, can be taken as $\widehat{D}$ when $\theta = \pi$  and $\mathbf{u} = \mathbf{0}$, which gives $D_{\text{min},\mathcal{C}} = \sqrt{2}\pi$. Thus, when $\widehat{D} < D_{\text{min},\mathcal{C}}$, it necessarily follows that $\theta < \pi$, avoiding the non-differentiable points of type i. Additionally, when $\widehat{D} > 0$, the non-differentiable points of type ii are also avoided. Therefore, the condition $0 < \widehat{D} < \sqrt{2}\pi$ guarantees that $\widehat{D}$ is differentiable, as required in \cref{def:distance-D-hat-arbitrary-elements}.
% \begin{comment}
\subsubsection{Components computation}
Although it may not be trivial, the components of the vector field can be computed explicitly. First, observe that the tangent component $\boldsymbol{\xi}_T$ depends on the nearest point on the curve and the derivative of the curve at this point. Since the curve is parametrized, we already have the equation that describes it, implying that the derivative is also known. Therefore, the tangent component $\boldsymbol{\xi}_T = \invSL\bigl(\frac{d\mathbf{H}_d(s^*)}{ds}\mathbf{H}_d(s^*)^{-1}\bigr)$ can be computed explicitly.

To compute the normal component $\boldsymbol{\xi}_N$, we need to evaluate $\text{L}_{\mathbf{V}}[\widehat{D}](\mathbf{H}, \mathbf{H}_d(s^*))$. Two approaches can be used for this computation. The first is a numerical approach, where we evaluate the left-hand side of \eqref{eq:Leq} for $\boldsymbol{\zeta} = \mathbf{e}_i$ with a small $\varepsilon$. The second approach involves computing the explicit $\Lop$ operator of $\widehat{D}$ with respect to $\mathbf{H}$, which we will now derive.

First, note that the EE-distance is symmetric, i.e., $\bigl\|\log(\mathbf{V}^{-1}\mathbf{W})\bigr\|_F = \bigl\|\log(\mathbf{W}^{-1}\mathbf{V})\bigr\|_F$. Let $\mathbf{Z}=\mathbf{H}_d(s^*)^{-1}\mathbf{H}$, then using expression \eqref{eq:explicit-EE-distance-SE3}, we define the following equivalent function:
\begin{align}
    \widehat{E}(\mathbf{Z}) \triangleq \widehat{D}(\mathbf{H}, \mathbf{H}_d(s^*)) = \sqrt{2\theta^2 + \mathbf{u}^\top\bar{\mathbf{X}}\mathbf{u}},
    \label{eq:explicit-EE-dista-SE3-component-Ehat}
\end{align}
for which the $\Lop$ operator can be computed as
\begin{align}
    \Lop[\widehat{E}](\mathbf{Z}) = \frac{1}{2 \sqrt{2\theta^2 + \mathbf{u}^\top\bar{\mathbf{X}}\mathbf{u}}}\text{L}\bigl[2\theta^2 + \mathbf{u}^\top\bar{\mathbf{X}}\mathbf{u}\bigr](\mathbf{Z}),
\end{align}
which in turn can be expressed by 
\begin{align}
    \Lop[\widehat{E}](\mathbf{Z}) = \frac{4\theta\text{L}[\theta] + \Lop\bigl[\sum_{i=1}^{3}\sum_{j=1}^{3}\mathbf{u}_i\mathbf{u}_j\bar{\mathbf{X}}_{ij}\bigr](\mathbf{Z})}{2 \widehat{E}(\mathbf{Z})}. \label{eq:explicit-derivative-L-Ehat-p1}
\end{align}
The computation of the two $\Lop$ operators in \eqref{eq:explicit-derivative-L-Ehat-p1} is rather lengthy and is provided in \cref{app:explicit-derivative-SE3}. However, note that these computations only rely on previously computed terms and the elements of $\mathbf{u}$ and $\mathbf{Q}$. For completeness, we present the expressions for these terms without the detailed derivation:
\begin{align}
    \text{L}[\theta](\mathbf{Z}) = \frac{-\cos\theta}{8\sin\theta}\mathbf{f} - \frac{\sin\theta}{2}\mathbf{g},
    \label{eq:explicit-EE-dista-SE3-component-Ltheta}
\end{align}
where 
\begin{align}
    \mathbf{f} &= 2\begin{bmatrix}
        \mathbf{0}& \{\mathbf{Q}^2\}_{23}-\{\mathbf{Q}^2\}_{32} & \{\mathbf{Q}^2\}_{31} - \{\mathbf{Q}^2\}_{13} & \{\mathbf{Q}^2\}_{12}-\{\mathbf{Q}^2\}_{21}
    \end{bmatrix},\label{eq:explicit-EE-dista-SE3-component-fvec}\\
    \mathbf{g} &= \begin{bmatrix}
        \mathbf{0}& \mathbf{Q}_{23}-\mathbf{Q}_{32} & \mathbf{Q}_{31} - \mathbf{Q}_{13} & \mathbf{Q}_{12}-\mathbf{Q}_{21}
    \end{bmatrix} \label{eq:explicit-EE-dista-SE3-component-gvec}.
\end{align}
The remaining $\Lop$ operator is expressed as
\begin{align}
    \Lop\Bigl[\sum_{i=1}^{3}\sum_{j=1}^{3}\mathbf{u}_i\mathbf{u}_j\bar{\mathbf{X}}_{ij}\Bigr](\mathbf{Z}) =  \sum_{i=1}^{3}\sum_{j=1}^{3}& \Bigl(2\Lop[\mathbf{u}_{i}](\mathbf{Z})\mathbf{u}_{j}\bar{\mathbf{X}}_{ij}
     +\mathbf{u}_{i}\mathbf{u}_{j}\Lop\bigl[\bar{\mathbf{X}}_{ij}\bigr](\mathbf{Z})\Bigr),
\end{align}
where
\begin{align}
    \Lop[\mathbf{u}_{i}](\mathbf{Z}) &= \begin{bmatrix}
        \delta_{1i} & \delta_{2i} & \delta_{3i} & \{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_1)\mathbf{u}\}_i & \{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_2)\mathbf{u}\}_i & \{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_3)\mathbf{u}\}_i 
    \end{bmatrix},\label{eq:explicit-EE-dista-SE3-component-Lui}\\
    \Lop[\bar{\mathbf{X}}_{ij}](\mathbf{Z}) &= \Lop[\beta_0](\mathbf{Z})\bigl(-2\delta_{ij}+ \mathbf{Q}_{ij} + \mathbf{Q}_{ji}\bigr) + \beta_0\Bigl(\Lop[\mathbf{Q}_{ij}](\mathbf{Z}) + \Lop[\mathbf{Q}_{ji}](\mathbf{Z})\Bigr) \label{eq:explicit-EE-dista-SE3-component-Xij}
\end{align}
in which $\delta_{ij}$ is the Kronecker delta, $\widehat{\mathcal{S}}:\mathbb{R}^3\to\mathfrak{so}(3)$ is a skew-symmetric matrix, $\widehat{\mathbf{e}}_i$ is the $i^{th}$ canonical basis vector in $\mathbb{R}^3$, and
\begin{align}
    \Lop[\beta_0](\mathbf{Z}) &= \frac{\theta^2\sin(\theta) - \theta - \sin(\theta) + \bigl(\theta + \sin(\theta)\bigr) \cos(\theta)}{2 (1 - \cos(\theta))^3} \Lop[\theta](\mathbf{Z}), \label{eq:explicit-EE-dista-SE3-component-Lbeta}\\
    \Lop[\mathbf{Q}_{ij}](\mathbf{Z}) &= \begin{bmatrix}
        \mathbf{0} & \bigl\{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_1)\mathbf{Q}\bigr\}_{ij} & \bigl\{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_2)\mathbf{Q}\bigr\}_{ij} & \bigl\{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_3)\mathbf{Q}\bigr\}_{ij}
    \end{bmatrix}. \label{eq:explicit-EE-dista-SE3-component-LQij}
\end{align}

To compute $\boldsymbol{\xi}_N$, we need to evaluate $\Lop_\mathbf{V}[\widehat{D}](\mathbf{H}, \mathbf{H}_d(s^*))$. However, by applying the chain rule, we can compute it via $\Lop[\widehat{E}](\mathbf{Z})$ as follows (see \cref{app:prop-Lop-chain-rule-SE3}):
\begin{align}
    \Lop_\mathbf{V}[\widehat{D}](\mathbf{H}, \mathbf{H}_d(s^*)) = \Lop[\widehat{E}](\mathbf{Z})\mathcal{Z}\bigl(\mathbf{H}_d(s^*)\bigr),
\end{align}
where $\mathcal{Z}\bigl(\mathbf{H}_d(s^*)\bigr)$ is computed as
\begin{align}
    \mathcal{Z}\bigl(\mathbf{H}_d(s^*)\bigr) = \begin{bmatrix}
        \mathbf{R}_d^\top(s^*) & -\mathbf{R}_d^\top(s^*)\widehat{\mathcal{S}}\bigl(\mathbf{p}_d(s^*)\bigr)\\
        \mathbf{0} & \mathbf{R}_d^\top(s^*)
    \end{bmatrix}, \label{eq:explicit-EE-dista-SE3-component-Zmap}
\end{align}
in which $\mathbf{R}_d(s^*)$ and $\mathbf{p}_d(s^*)$ are the rotation matrix and position of $\mathbf{H}_d(s^*)$, respectively. The computation of $\mathcal{Z}\bigl(\mathbf{H}_d(s^*)\bigr)$ is straightforward, and thus $\boldsymbol{\xi}_N$ can be computed explicitly. Algorithmically, the computation of $\Lop_\mathbf{V}[\widehat{D}](\mathbf{Z})$ is shown in \cref{alg:LN-SE3}.
\begin{algorithm}[H]
    \caption{Computation of $\text{L}_\mathbf{V}[\widehat{D}](\mathbf{Z})$ in $\text{SE}(3)$}
    \label{alg:LN-SE3}
    \begin{algorithmic}[1]
    \Statex \textbf{Input:} $\mathbf{H}_d(s^*)$, $\mathbf{H}$
    \Statex \textbf{Output:} $\text{L}_\mathbf{V}[\widehat{D}](\mathbf{Z})$ 
    
    \State $\mathbf{Z} \gets \mathbf{H}_d(s^*)^{-1} \mathbf{H}$
    \State Extract rotation matrix $\mathbf{Q}$ and translation $\mathbf{u}$ from $\mathbf{Z}$
    \State $u \gets \frac{1}{2} (\tr(\mathbf{Q}) - 1)$
    \State $v \gets \frac{1}{2\sqrt{2}} \|\mathbf{Q} - \mathbf{Q}^\top\|_F$
    \State $\theta \gets \atantwo(v, u)$
    \State $\beta_0 \gets \frac{2 - 2u - \theta^2}{4(1 - u)^2}$
    \State $\bar{\mathbf{X}} \gets \mathbf{I}(1 - 2\beta_0) + (\mathbf{Q} + \mathbf{Q}^\top)\beta_0$
    \State $\widehat{E}(\mathbf{Z}) \gets$  $\sqrt{2\theta^2 + \mathbf{u}^\top\bar{\mathbf{X}}\mathbf{u}}$
    \State $\mathbf{f} \gets$ $2\begin{bmatrix}
        \mathbf{0}& \{\mathbf{Q}^2\}_{23}-\{\mathbf{Q}^2\}_{32} & \{\mathbf{Q}^2\}_{31} - \{\mathbf{Q}^2\}_{13} & \{\mathbf{Q}^2\}_{12}-\{\mathbf{Q}^2\}_{21}
    \end{bmatrix}$
    \State $\mathbf{g} \gets$ $\begin{bmatrix}
        \mathbf{0}& \mathbf{Q}_{23}-\mathbf{Q}_{32} & \mathbf{Q}_{31} - \mathbf{Q}_{13} & \mathbf{Q}_{12}-\mathbf{Q}_{21}
    \end{bmatrix}$
    \State $\Lop[\theta] \gets$ $\frac{-\cos\theta}{8\sin\theta}\mathbf{f} - \frac{\sin\theta}{2}\mathbf{g}$
    \State $\Lop[\beta_0] \gets$ $\frac{\theta^2\sin(\theta) - \theta - \sin(\theta) + \bigl(\theta + \sin(\theta)\bigr) \cos(\theta)}{2 (1 - \cos(\theta))^3} \Lop[\theta]$
    \State Initialize $\Lop[\mathbf{u}^\top \bar{\mathbf{X}} \mathbf{u}] \gets 0$ 

    \For{$i \gets 1$ to $3$}
        \State $\Lop[\mathbf{u}_i] \gets$ $\begin{bmatrix}
            \delta_{1i} & \delta_{2i} & \delta_{3i} & \{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_1)\mathbf{u}\}_i & \{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_2)\mathbf{u}\}_i & \{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_3)\mathbf{u}\}_i 
        \end{bmatrix}$
        \For{$j \gets 1$ to $3$} 
            \State $\Lop[\mathbf{Q}_{ij}] \gets$ $\begin{bmatrix}
                \mathbf{0} & \bigl\{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_1)\mathbf{Q}\bigr\}_{ij} & \bigl\{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_2)\mathbf{Q}\bigr\}_{ij} & \bigl\{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_3)\mathbf{Q}\bigr\}_{ij}
            \end{bmatrix}$
            \State $\Lop[\mathbf{Q}_{ji}] \gets$ $\begin{bmatrix}
                \mathbf{0} & \bigl\{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_1)\mathbf{Q}\bigr\}_{ji} & \bigl\{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_2)\mathbf{Q}\bigr\}_{ji} & \bigl\{\widehat{\mathcal{S}}(\widehat{\mathbf{e}}_3)\mathbf{Q}\bigr\}_{ji}
            \end{bmatrix}$
            \State $\Lop[\bar{\mathbf{X}}_{ij}]\gets$ $\Lop[\beta_0]\bigl(-2\delta_{ij}+ \mathbf{Q}_{ij} + \mathbf{Q}_{ji}\bigr) + \beta_0\Bigl(\Lop[\mathbf{Q}_{ij}] + \Lop[\mathbf{Q}_{ji}]\Bigr)$
            % \State Accumulate $\Lop[u^\top X u]$:
        
            \State $\Lop[\mathbf{u}^\top \bar{\mathbf{X}} \mathbf{u}] \gets$ $\Lop[\mathbf{u}^\top \bar{\mathbf{X}} \mathbf{u}]
            + 2\Lop[\mathbf{u}_i]\mathbf{u}_j \bar{\mathbf{X}}_{ij} 
            + \mathbf{u}_i \mathbf{u}_j \Lop[\bar{\mathbf{X}}_{ij}]
            $
        \EndFor
    \EndFor
    
    \State $\Lop[\widehat{E}] \gets \frac{4\theta\Lop[\theta] + \Lop[\mathbf{u}^\top \bar{\mathbf{X}} \mathbf{u}]}{2\widehat{E}(\mathbf{Z})}$
    \State $\mathcal{Z}\bigl(\mathbf{H}_d(s^*)\bigr) \gets$\eqref{eq:explicit-EE-dista-SE3-component-Zmap}
    \State $\Lop_\mathbf{V}[\widehat{D}] \gets \Lop[\widehat{E}]\mathcal{Z}\bigl(\mathbf{H}_d(s^*)\bigr)$
    \end{algorithmic}
\end{algorithm}